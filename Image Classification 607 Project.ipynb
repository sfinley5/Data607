{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3a41c56",
   "metadata": {},
   "source": [
    "# Image Classification for Amazon Products\n",
    "\n",
    "**Purpose**:\n",
    "\n",
    "Image classification is a crucial task for online marketplaces such as Amazon, which rely on images to showcase their products to customers. Amazon has a vast array of products, from electronics to clothing, and image classification can help to accurately categorize these products. In this proposal, we will discuss a machine-learning project for the image classification of Amazon products.\n",
    "Specifically, we will use our own customized web scraping tool to download thousands of images for a range of human wearable products, including Earbuds, VR sets, Fitness trackers, Hearing Aids, Watches, Sunglasses, and Hats. Our purpose is to build a model that can accurately classify the products in the images.\n",
    "\n",
    "\n",
    "**Methodology**:\n",
    "\n",
    "The first step in this project is data preprocessing. The images are resized to a standard size, and the pixel values are normalized to a range of [0, 1]. The images are also labelled based on the product category to which they belong. Then, the data is split into training and validation sets, where the training set is used to train the model, and the validation set is used to evaluate the performance of the model during training.\n",
    "As an exploration step, we will first use some conventional machine learning models like logistic regression, K-nearest neighbours (KNN), support vector machines (SVM), and Gaussian Bayes Classifier. The model is trained using the labelled images, and its performance is evaluated on a separate validation dataset with a cross-validation technique. To reduce computational power, there is a dimensionality reduction method using principal component analysis (PCA) on top of each training model. PCA can be used to reduce the dimensionality of the image data by identifying the most important pixels. This can improve the efficiency of machine learning algorithms and reduce overfitting. Eventually, each trained model is then used to classify new images into their respective product categories.\n",
    "Contrary to conventional machine learning models, we will also use deep learning methods like Convolutional Neural Networks (CNN) to classify images, which is probably a better way to deal with complex datasets. This method will be covered in the later classes, the general idea here is the model applies convolutional filters to the input image, which extract features at different spatial scales. The extracted features are then fed into a series of fully connected layers that perform the classification task. The output of the model is a softmax layer that predicts the probability distribution over the product categories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25164086",
   "metadata": {},
   "source": [
    "First we will try a range of conventional machine learning models like Random Forest Classifier, KNN, Decision Tree Classifier, and Naive Bayes classifier. Later on we will also implement Deep Learning like CNN.\n",
    "\n",
    "The overall layout for this analysis is:\n",
    "1. import all required packages\n",
    "2. Load the data and label each image\n",
    "3. Visualialize some figures and process them\n",
    "4. Try differetnt machine learning modesl, find the best hypter parameters, and evaluate respective performance\n",
    "5. Use the trained model to do some prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c2035c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "\n",
    "#need to pip install opencv-python\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,mean_squared_error \n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c03ea05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have in total 12 different classes.\n",
      "And they are:\n",
      " tshirt, sunglasses, watches, speaker, chair, pens, shorts, phone, earbuds, hat, shoes, bottle.\n"
     ]
    }
   ],
   "source": [
    "#Get the total classes we have\n",
    "class_names = [class_name for class_name in os.listdir(\"./images\") if not class_name.startswith(\".\")]\n",
    "class_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n",
    "nb_classes = len(class_names)\n",
    "IMAGE_SIZE = (150, 150)\n",
    "print(f\"We have in total {nb_classes} different classes.\"+\n",
    "      f\"\\nAnd they are:\\n {', '.join(classes for classes in class_names)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29451f1",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f821dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# OS.walk() generate the file names in a directory tree by walking the tree either top-down or bottom-up.\n",
    "# For each directory in the tree rooted at directory top (including top itself), \n",
    "# it yields a 3-tuple (dirpath, dirnames, filenames).\n",
    "# For example, we have 12 folder in ./images, it will loop through 13 times = root + 12 folders\n",
    "# Read more in https://www.geeksforgeeks.org/os-walk-python/\n",
    "# '''\n",
    "# class_name = []\n",
    "# for root, dirs, files in os.walk(\"./images\", topdown = True):\n",
    "#     for name in files:\n",
    "#         print(os.path.join(root, name))\n",
    "\n",
    "# for i in range(10):\n",
    "#     plt.imshow(images[i].astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc7cd0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data from each folder\n",
    "images = []\n",
    "labels = []\n",
    "IMAGE_SIZE = (150, 150)\n",
    "\n",
    "for folder in os.listdir(\"./images\"):\n",
    "    #Because there are some configure file also sitting there\n",
    "    if folder.startswith(\".\"):\n",
    "        continue\n",
    "    label = class_names_label[folder]\n",
    "    for file in os.listdir(os.path.join(\"./images\", folder)):\n",
    "        # Get the path name of the image\n",
    "        if file.startswith(\".\"):\n",
    "            continue\n",
    "        img_path = os.path.join(\"./images\", folder, file)\n",
    "        #open and resize the image, read in as 3d array\n",
    "        image = cv2.imread(img_path)\n",
    "        #cv2.cvtColor() method is used to convert an image from one color space to another.\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #OpenCV provides the function cv2. resize() to resize an image. Resizing in OpenCV \n",
    "        #is referred to as scaling. We can resize an image by specifying the image size or scaling factor. \n",
    "        #The aspect ratio is preserved when we specify the scaling factor.\n",
    "        image = cv2.resize(image, IMAGE_SIZE)\n",
    "        \n",
    "        # Append the image and its corresponding label to the output\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "        \n",
    "images = np.array(images, dtype = 'float32')\n",
    "labels = np.array(labels, dtype = 'int32')\n",
    "\n",
    "#Shuffle arrays or sparse matrices in a consistent way.\n",
    "#This is a convenience alias to resample(*arrays, replace=False) to do random permutations of the collections.\n",
    "#otherwise imaages are grouped all together based on their classes\n",
    "images, labels = shuffle(images, labels, random_state=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96688365",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
